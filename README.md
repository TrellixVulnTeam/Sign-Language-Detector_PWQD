## **<h2 align="center">Sign-Language-Detector</h2>**

# Description
Sign language is distinct from spoken languages and does not have standard written forms. However, the vast majority of communications technologies are designed to support spoken or written languages; which excludes sign languages. Most people do not know sign language and as a result, many communication barriers exist for deaf sign language users. Sign language processing would help break down these barriers for sign language users. We are trying to train a machine learning model on American sign Language recognition. 

This project has real time Object detection using Tensonflow framework and the camera to interpret Sign Language. The interface is created using ReactJS with camera input displaying the video with matching framerate of the display. For object storage I have used AWS S3 and used ReactJS to fetch pre-trained python models.

<img src="https://github.com/ziasyed2000/Sign-Language-Detector/blob/main/detection.gif" />



## Technologies used:
<p align="center">
<img src="https://github.com/devicons/devicon/blob/master/icons/react/react-original.svg" width="70" height="70"/>
<img src="https://github.com/devicons/devicon/blob/master/icons/tensorflow/tensorflow-original.svg" alt="css3" width="70" height="70"/>
<img src="https://github.com/devicons/devicon/blob/master/icons/python/python-original.svg" alt="javascript" width="70" height="70"/>
</p>

---

## Features
- [x] Real time object detection.
- [x] Object tracking window.
- [x] Detection Certainty Level (0-100).
- [x] AWS S3 Object storage.
